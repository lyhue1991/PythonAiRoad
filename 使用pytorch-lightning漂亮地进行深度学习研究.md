# ä½¿ç”¨pytorch-lightningæ¼‚äº®åœ°è¿›è¡Œæ·±åº¦å­¦ä¹ ç ”ç©¶


pytorch-lightning æ˜¯å»ºç«‹åœ¨pytorchä¹‹ä¸Šçš„é«˜å±‚æ¬¡æ¨¡å‹æ¥å£ã€‚

pytorch-lightning ä¹‹äº pytorchï¼Œå°±å¦‚åŒkerasä¹‹äº tensorflow.

é€šè¿‡ä½¿ç”¨ pytorch-lightningï¼Œç”¨æˆ·æ— éœ€ç¼–å†™è‡ªå®šä¹‰è®­ç»ƒå¾ªç¯å°±å¯ä»¥éå¸¸ç®€æ´åœ°åœ¨CPUã€å•GPUã€å¤šGPUã€ä¹ƒè‡³å¤šTPUä¸Šè®­ç»ƒæ¨¡å‹ã€‚

æ— éœ€è€ƒè™‘æ¨¡å‹å’Œæ•°æ®åœ¨cpu,cudaä¹‹é—´çš„ç§»åŠ¨ï¼Œå¹¶ä¸”å¯ä»¥é€šè¿‡å›è°ƒå‡½æ•°å®ç°CheckPointå‚æ•°ä¿å­˜ï¼Œå®ç°æ–­ç‚¹ç»­è®­åŠŸèƒ½ã€‚

<!-- #region -->
ä¸€èˆ¬æŒ‰ç…§å¦‚ä¸‹æ–¹å¼ å®‰è£…å’Œ å¼•å…¥ pytorch-lightning åº“ã€‚

```bash
#å®‰è£…
pip install pytorch-lightning
```

```python 
#å¼•å…¥
import pytorch_lightning as pl 
```

é¡¾åæ€ä¹‰ï¼Œå®ƒå¯ä»¥å¸®åŠ©æˆ‘ä»¬æ¼‚äº®(pl)åœ°è¿›è¡Œæ·±åº¦å­¦ä¹ ç ”ç©¶ã€‚ğŸ˜‹ğŸ˜‹ 


<!-- #endregion -->

```python

```

## ä¸€ï¼Œpytorch-lightningçš„è®¾è®¡å“²å­¦


pytorch-lightning çš„æ ¸å¿ƒè®¾è®¡å“²å­¦æ˜¯å°† æ·±åº¦å­¦ä¹ é¡¹ç›®ä¸­çš„ ç ”ç©¶ä»£ç (å®šä¹‰æ¨¡å‹) å’Œ å·¥ç¨‹ä»£ç  (è®­ç»ƒæ¨¡å‹) ç›¸äº’åˆ†ç¦»ã€‚

ç”¨æˆ·åªéœ€ä¸“æ³¨äºç ”ç©¶ä»£ç (pl.LightningModule)çš„å®ç°ï¼Œè€Œå·¥ç¨‹ä»£ç å€ŸåŠ©è®­ç»ƒå·¥å…·ç±»(pl.Trainer)ç»Ÿä¸€å®ç°ã€‚

æ›´è¯¦ç»†åœ°è¯´ï¼Œæ·±åº¦å­¦ä¹ é¡¹ç›®ä»£ç å¯ä»¥åˆ†æˆå¦‚ä¸‹4éƒ¨åˆ†ï¼š

* ç ”ç©¶ä»£ç  (Research code)ï¼Œç”¨æˆ·ç»§æ‰¿LightningModuleå®ç°ã€‚
* å·¥ç¨‹ä»£ç  (Engineering code)ï¼Œç”¨æˆ·æ— éœ€å…³æ³¨é€šè¿‡è°ƒç”¨Trainerå®ç°ã€‚
* éå¿…è¦ä»£ç  ï¼ˆNon-essential research codeï¼Œlogging, etc...ï¼‰ï¼Œç”¨æˆ·é€šè¿‡è°ƒç”¨Callbackså®ç°ã€‚
* æ•°æ® (Data)ï¼Œç”¨æˆ·é€šè¿‡torch.utils.data.DataLoaderå®ç°ã€‚



```python

```

## äºŒï¼Œpytorch-lightningä½¿ç”¨èŒƒä¾‹


ä¸‹é¢æˆ‘ä»¬ä½¿ç”¨ministå›¾ç‰‡åˆ†ç±»é—®é¢˜ä¸ºä¾‹ï¼Œæ¼”ç¤ºpytorch-lightningçš„æœ€ä½³å®è·µã€‚



**1ï¼Œå‡†å¤‡æ•°æ®**

```python
import torch 
from torch import nn 

import torchvision 
from torchvision import transforms

```

```python
transform = transforms.Compose([transforms.ToTensor()])

ds_train = torchvision.datasets.MNIST(root="./minist/",train=True,download=True,transform=transform)
ds_valid = torchvision.datasets.MNIST(root="./minist/",train=False,download=True,transform=transform)

dl_train =  torch.utils.data.DataLoader(ds_train, batch_size=128, shuffle=True, num_workers=4)
dl_valid =  torch.utils.data.DataLoader(ds_valid, batch_size=128, shuffle=False, num_workers=4)

print(len(ds_train))
print(len(ds_valid))

```

```
Done!
60000
10000
```


**2ï¼Œå®šä¹‰æ¨¡å‹**

```python
import pytorch_lightning as pl 
import datetime

class Model(pl.LightningModule):
    
    def __init__(self):
        super().__init__()
        self.layers = nn.ModuleList([
            nn.Conv2d(in_channels=1,out_channels=32,kernel_size = 3),
            nn.MaxPool2d(kernel_size = 2,stride = 2),
            nn.Conv2d(in_channels=32,out_channels=64,kernel_size = 5),
            nn.MaxPool2d(kernel_size = 2,stride = 2),
            nn.Dropout2d(p = 0.1),
            nn.AdaptiveMaxPool2d((1,1)),
            nn.Flatten(),
            nn.Linear(64,32),
            nn.ReLU(),
            nn.Linear(32,10)]
        )
        
    def forward(self,x):
        for layer in self.layers:
            x = layer(x)
        return x
    
    #å®šä¹‰loss,ä»¥åŠå¯é€‰çš„å„ç§metrics
    def training_step(self, batch, batch_idx):
        x, y = batch
        prediction = self(x)
        loss = nn.CrossEntropyLoss()(prediction,y)
        return loss
    
    #å®šä¹‰optimizer,ä»¥åŠå¯é€‰çš„lr_scheduler
    def configure_optimizers(self):
        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)
        return {"optimizer":optimizer}
    
    def validation_step(self, batch, batch_idx):
        loss = self.training_step(batch,batch_idx)
        return {"val_loss":loss}
    
    def test_step(self, batch, batch_idx):
        loss = self.training_step(batch,batch_idx)
        return {"test_loss":loss}
    
  
```

**3ï¼Œè®­ç»ƒæ¨¡å‹**

```python
pl.seed_everything(1234)
model = Model() 


ckpt_callback = pl.callbacks.ModelCheckpoint(
    monitor='val_loss',
    save_top_k=1,
    mode='min'
)

# gpus=0 åˆ™ä½¿ç”¨cpuè®­ç»ƒï¼Œgpus=1åˆ™ä½¿ç”¨1ä¸ªgpuè®­ç»ƒï¼Œgpus=2åˆ™ä½¿ç”¨2ä¸ªgpuè®­ç»ƒï¼Œgpus=-1åˆ™ä½¿ç”¨æ‰€æœ‰gpuè®­ç»ƒï¼Œ
# gpus=[0,1]åˆ™æŒ‡å®šä½¿ç”¨0å·å’Œ1å·gpuè®­ç»ƒï¼Œ gpus="0,1,2,3"åˆ™ä½¿ç”¨0,1,2,3å·gpuè®­ç»ƒ
# tpus=1 åˆ™ä½¿ç”¨1ä¸ªtpuè®­ç»ƒ

trainer = pl.Trainer(max_epochs=5,gpus=0,callbacks = [ckpt_callback]) 

#æ–­ç‚¹ç»­è®­
#trainer = pl.Trainer(resume_from_checkpoint='./lightning_logs/version_31/checkpoints/epoch=02-val_loss=0.05.ckpt')

trainer.fit(model,dl_train,dl_valid)

```

```
Global seed set to 1234
GPU available: False, used: False
TPU available: None, using: 0 TPU cores

  | Name   | Type       | Params
--------------------------------------
0 | layers | ModuleList | 54.0 K
--------------------------------------
54.0 K    Trainable params
0         Non-trainable params
54.0 K    Total params
Epoch 4: 100% >>>>>>>>>>>>>>>>>>>>>>>>>>>> 158/158 [00:19<00:00, 8.08it/s, loss=0.138, v_num=34]
```

```python

```

**4ï¼Œè¯„ä¼°æ¨¡å‹**

```python
result = trainer.test(model, test_dataloaders=dl_valid)
print(result)
```

```
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_loss': tensor(0.0047)}
--------------------------------------------------------------------------------
[{'test_loss': 0.004680501762777567}]
```


**5ï¼Œä½¿ç”¨æ¨¡å‹**

```python
data,label = next(iter(dl_valid))
model.eval()
prediction = model(data)
print(prediction)

```

```
tensor([[ -5.1149,  -6.1142,   2.0591,  ...,   7.0609,  -5.4144,   0.5222],
        [ -2.2989,  -5.6076,   3.7343,  ...,  -1.8391,  -6.4941,  -3.4076],
        [  0.9215,   6.9357,  -1.9887,  ...,  -2.2996,  -0.8034,  -3.2993],
        ...,
        [ -4.5674,  -6.0223,  -0.9309,  ...,  -3.5468,   0.3367,   4.5473],
        [  4.3023,  -4.1629,  -1.2742,  ...,  -4.2527,  -2.3449,  -2.5585],
        [ -3.8913, -10.3790,  -1.7804,  ...,  -4.6757,  -0.7428,   1.0305]],
       grad_fn=<AddmmBackward>)
```


**6ï¼Œä¿å­˜æ¨¡å‹**


æœ€ä¼˜æ¨¡å‹é»˜è®¤ä¿å­˜åœ¨ trainer.checkpoint_callback.best_model_path çš„ç›®å½•ä¸‹ï¼Œå¯ä»¥ç›´æ¥åŠ è½½ã€‚

```python
print(trainer.checkpoint_callback.best_model_path)
print(trainer.checkpoint_callback.best_model_score)
```

```
/Users/liangyun/CodeFiles/PythonAiRoad/lightning_logs/version_34/checkpoints/epoch=04-val_loss=0.00.ckpt
tensor(0.0047)

```

```python
model_clone = Model.load_from_checkpoint(trainer.checkpoint_callback.best_model_path)
trainer_clone = pl.Trainer(max_epochs=3) 
result = trainer_clone.test(model_clone,dl_valid)
print(result)

```

```
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_loss': tensor(0.0047)}
--------------------------------------------------------------------------------
[{'test_loss': 0.004680501762777567}]
```


å¦‚æœå¯¹æœ¬æ–‡å†…å®¹ç†è§£ä¸Šæœ‰éœ€è¦è¿›ä¸€æ­¥å’Œä½œè€…äº¤æµçš„åœ°æ–¹ï¼Œæ¬¢è¿åœ¨å…¬ä¼—å·"ç®—æ³•ç¾é£Ÿå±‹"ä¸‹ç•™è¨€ã€‚ä½œè€…æ—¶é—´å’Œç²¾åŠ›æœ‰é™ï¼Œä¼šé…Œæƒ…äºˆä»¥å›å¤ã€‚

ä¹Ÿå¯ä»¥åœ¨å…¬ä¼—å·åå°å›å¤å…³é”®å­—ï¼šåŠ ç¾¤ï¼ŒåŠ å…¥è¯»è€…äº¤æµç¾¤å’Œå¤§å®¶è®¨è®ºã€‚

![](./data/ç®—æ³•ç¾é£Ÿå±‹äºŒç»´ç .png)



